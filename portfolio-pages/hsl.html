<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Emma Griffiths - AR Gestural Controls for SPHEREs Satellites</title>
    <link rel="stylesheet" href="styles.css">
    <style>
        body {
            font-family: Arial, sans-serif;
            background-color: #000000;
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        nav {
            display: flex;
            justify-content: center;
            background-color: #000000;
            /* padding: 10px; */
            position: fixed;
            top: 0;
            left: 0;
            margin: 0px;
            right: 0;
            width: 100%;
        }

        nav a {
            color: white;
            text-decoration: none;
            padding: 4px;
            margin: 0 5px;
            font-size: small;
            /* position: fixed;
            top: 0;
            left: 0;
            margin: 0px;
            right: 0;
            width: 100%; */
            font-weight: bold;
        }

        header {
            background-color: #000000;
            padding: 10px;
            text-align: center;
            color: white;
        }

        section {
            padding: 20px;
        }

        footer {
            background-color: #000000;
            padding: 10px;
            text-align: center;
            color: white;
        }

        /* Column container */
        .row2 {  
            display: flex;
            flex-wrap: wrap;
        }

        /* Create two unequal columns that sits next to each other */
        /* Sidebar/left column */
        .side2 {
            flex: 50%;
            padding: 20px;
            background-color: #101010;
        }

        /* Main column */
        .main2 {
            flex: 30%;
            padding: 20px;
            background-color: #101010;
        }

        .row {  
            display: flex;
            flex-wrap: wrap;
        }

        .column1 {
            flex: 50%;
            background-color: #101010;
        }

        .column2 {
            flex: 50%;
            background-color: #101010;
        }

        .center {
            display: block;
            margin-left: auto;
            margin-right: auto;
            width: 50%;
        }

        @media screen and (max-width: 700px) {
            .row, .row2 {   
                flex-direction: column;
            }
        }

    </style>
</head>
<body>

    <nav>
        <a href="https://egriff44.github.io/">[HOME]</a>
        <a href="https://egriff44.github.io/resume">[RESUME]</a>
        <a href="https://egriff44.github.io/portfolio">[PORTFOLIO]</a>
        <a href="https://egriff44.github.io/aboutme">[ABOUT ME]</a>
    </nav>

    <div style="background-color: #101010;">
        <div style="padding-left: 50px;padding-right: 50px;">
            <br>
            <br>
            <h1 style="color: #ad7372;">AR Gestural Controls for SPHEREs Satellites - Work with HSL-AeroAstro-MIT</h1>
            <br>
            <br>
            <div class="row2">
                <div class="side2">
                    <div style="color:#898baa;background-color: #6b1b06;border: 6px solid;border-color: #898baa;max-width: 250px;">
                        <center><h2>description</h2></center>
                    </div>
                    <br>
                    <p style="color:#8d8f8f;">
                        Worked with the Human Systems Lab (HSL) in MIT AeroAstro to develop gestural controls for MIT-developed SPHEREs 
                        (Synchronized Position Hold Engage and Reorient Experimental Satellite), 
                        making it possible to interface with and control the satellites with Microsoft HoloLens 
                        augmented reality via Unity in order to investigate how immersive technology can improve an astronautâ€™s 
                        spatial awareness when performing extravehicular activities. This also included designing a training 
                        program to onboard users with the SPHEREs/HoloLens technology.
                    </p>
                </div>
                <div class="main2">
                    <center>
                        <div style="color:#645c62;background-color: #8d8f8f;border: 8px solid;border-color: #645c62;max-width: 350px;">
                            <center><h2>skills used/developed</h2></center>
                        </div>
                        <br>
                        <p style="color:#8d8f8f;">
                            -  Unity/C#
                            <br>
                            -  Augmented Reality
                            <br>
                            -  Microsoft HoloLens
                            <br>
                            -  Experiment Design
                            <br>
                            -  Human Factors Engineering
                            <br>
                            -  Human-centered Studies
                            <br>
                            -  Training Program Design
                            <br>
                        </p>
                    </center>
                </div>
            </div>
            <div style="color:#b39d9d;background-color: #722131;border: 6px solid;border-color: #b39d9d;max-width: 250px;">
                <center><h2>documentation</h2></center>
            </div>
            <div>
                <br>
                <p style="color:#8d8f8f;">
                    The current methods to complete exterior inspection tasks and EVA require using ISS exterior cameras, 
                    the Canadarm, and humans themselves. This project proposes a way to more efficiently complete these 
                    tasks using the SPHERES robots as a testbed for future free-flyer inspectors. For example, one of the 
                    goals is to transform the traditional 2D environment that is created by a camera into a 3D model that a 
                    human could interpret faster and use to make better informed decisions. To help understand how humans 
                    will be interacting with the SPHERES robots, the project will be focused on examining different modes of 
                    communicating with the SPHERES, including gestural control. My project will focus on developing gestural 
                    controls for controlling the SPHERES motion using an augmented reality interface, the HoloLens, to navigate 
                    a simulated virtual environment. To complete this research, ground-based SPHERES will be utilized. 
                    Unlike the SPHERES in space with six degrees of freedom, these will only involve 3 degrees of freedom. 
                    They operate in a similar manner as a hovercraft, gliding on a cushion of air. These simulated tests 
                    will help us to improve and understand the interaction between humans and the SPHERES robots, allowing us 
                    to improve the controls technology and the virtual environment.
                    <br>
                    <br>
                    The overall aim of this project was to develop a method by which autonomous robotic systems (with some 
                    aspect of human control) can replace human function and their part in completing tasks such as EVAs 
                    and exterior inspection tasks, such as looking for micrometeorites. The use of SPHERES in this research 
                    will help us better understand and model what the ideal autonomous robotic system would entail and how 
                    humans could efficiently interact with it.
                    <br>
                    <br>
                    Personal Contribution:
                    <br>
                    My work in this project included developing and implementing gestural controls for controlling the SPHERES 
                    motion using Unity and the Microsoft Hololens. Gesturally-controlled Augmented Reality had not
                    previously been applied to a scenario of commanding free-flying robots on-orbit. This work included 
                    utilizing gaze tracking and tap/pinch/two-handed gestures (for rotating/scaling/moving objects) to set waypoints for 
                    path planning in order to inspect anomalies around the simulated space station (tested with the SPHEREs). 
                    This work supported Jessica Eve Todd's MIT Master's Thesis, <a href="https://dspace.mit.edu/handle/1721.1/124180?show=full" target="_blank">'Commanding small satellites for simulated spacecraft inspections using augmented reality'</a>.
                    <br>
                    <br>
                </p>
            </div>
            <div>
                <p style="color:#8d8f8f;">Waypoint Controls (all images from linked paper):</p>
                <br>
                <img src="./references/waypoint.png" alt="Waypoint Controls" class="center">
                <br>
                <br>
                <p style="color:#8d8f8f;">Controls in Simulation:</p>
                <br>
                <img src="./references/controls.png" alt="Waypoint Controls Sim" class="center">
                <br>
                <br>
                <p style="color:#8d8f8f;">Proposed SPHEREs Experimental Setup:</p>
                <br>
                <img src="./references/simsetup.png" alt="Sim Setup" class="center">
                <br>
                <br>
            </div>
        </div>
    </div>
    

    <footer>
        <p>&copy; 2024 Emma Griffiths - Personal Website</p>
    </footer>

</body>
</html>
